# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EFh7iuK5kGAm-sPBdXmsBPtbQu0SdmgE
"""

#Sentiment analysis program twitter

#import libraries
import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

from google.colab import files
files.upload()

df1 = pd.read_csv('Combined_News_DJIA.csv')
df2 = pd.read_csv('datasets_129_792900_upload_DJIA_table.csv')

df1.head(3)

df1.shape

df2.head(3)

df2.shape

#Merge the data set
merge = df1.merge(df2, how ='inner',on='Date', left_index=True)

merge.head(3)

#Combine top news headlines
headlines = []

for row in range(0,len(merge.index)):
  headlines.append(' '.join(str(x) for x in merge.iloc[row,2:27]))

headlines[0]

#Clean the data
clean_headlines=[]

for i in range(0,len(headlines)):
  clean_headlines.append(re.sub("b[(')]",'',headlines[i]))
  clean_headlines[i] = re.sub('b[(")]','',clean_headlines[i])
  clean_headlines[i]=re.sub("\'",'',clean_headlines[i])

clean_headlines[0]

#Add cleaned headlines to merge dataset
merge['Combined News'] = clean_headlines

merge['Combined News'][0]

def get_subj(text):
  return TextBlob(text).sentiment.subjectivity

def get_pol(text):
  return TextBlob(text).sentiment.polarity

#Create two columns
merge['Subjectivity'] = merge['Combined News'].apply(get_subj)
merge['Polarity'] = merge['Combined News'].apply(get_pol)

merge.head(3)

#Function to get sentiment score
def get_sent(text):
  sia = SentimentIntensityAnalyzer()
  sentiment= sia.polarity_scores(text)
  return sentiment

#Each day score
compound=[]
neg = []
pos = []
neu=[]
SIA=0

for i in range(0,len(merge['Combined News'])):
  SIA = get_sent(merge['Combined News'][i])
  compound.append(SIA['compound'])
  neg.append(SIA['neg'])
  pos.append(SIA['pos'])
  neu.append(SIA['neu'])

merge['Compound'] = compound
merge['Negative'] = neg
merge['Positive'] = pos
merge['Neutral'] = neu

merge.head(3)

keep_Col=['Open','High','Low','Volume','Subjectivity','Polarity','Compound','Negative','Positive','Neutral','Label']
df = merge[keep_Col]

X = df
X = np.array(X.drop(['Label'],1))
y = np.array(df['Label'])

#Split the data
x_train, x_test, y_train,y_test = train_test_split(X,y,test_size=0.45,random_state=0)

#Create and train the model
model = LinearDiscriminantAnalysis().fit(x_train,y_train)

prediction = model.predict(x_test)
prediction

y_test

#Model Metrics
print(classification_report(y_test,prediction))